Med forskningen af søvn foretaget har vi fundet diverse redskaber, der er værd at have i mente ved implementeringen af en søvnestimeringsmetode.
Et redskab skal forstås som teori der kan være nyttigt i udviklingen eller verificeringen af søvnestimeringsmetoden.
Gennemgangen af disse redskaber tjener det formål at skabe overblik, over hvad man kan benytte i denne implementering.
Metoderne bygger på erfaringer oplyst af kilderne, samt teknikker der bygger på egen erfaring, men regnes for brugbare i denne sammenhæng.

\begin{description}[style=nextline]
\item[Vægtet gennemsnit]
Ud fra \citet{6563918} blev der understreget hvorledes et vægtet gennemsnit kan benyttes.
Idéen er at hver sensor kilde kan benyttes som en svag indikator på søvnlængde.
Imidlertid bør man ikke stole på udelukkende en kilde, da den søvnlængde man estimerer kan variere meget ved forskellig brug af smartphonen.
For så at have et mere sikkert estimat for søvnlængde, foretager man et såkaldt vægtet gennemsnit af hvert estimat, hvor kilder, der er mere sikre end andre får tillagt en større vægtning.

\item[Eksponentielt glidende gennemsnit]
Da man oplever støj på de forskellige sensorkilder kan man med fordel benytte et eksponentielt glidende gennemsnit.
Basalt set er et eksponentielt glidende gennemsnit en måde at udjævne tilfældige udsving i en serie af punkter.
Eksempelvis ved accelerations målinger oplever vi enkelte spikes på grund af støj, og disse kan udjævnes ved hjælp af det eksponentielle glidende gennemsnit.

\item[Krydsvalidering]
Når man udvikler sin estimeringsmetode skal man have en teknik til at estimere om ens model er tilpas præcis.
Problemet er at hvis man træner sin model på ens testdata og derefter tester på dette, risikerer man hvad der kaldes for overfitting.
Overfitting er hvor man tilpasser sin model så det virker godt på ens testdata, men ikke særligt godt på fremtidige datasæt.
Til at forhindre dette kan man foretage krydsvalidering
Ved krydsvalidering splitter man sit testdata op i en række delmængder.
Man foretager så analysen på en delmængde og validerer sin analyse på de resterende delmængder af datasæt.
For så at undgå overfitting afprøver man med forskellige partitioner af datasættet, og hvor ens præcision er estimeret som gennemsnittet af resultaterne af de datasæt man tester på.

% Stilstand
% Chen et al og andre
\end{description}